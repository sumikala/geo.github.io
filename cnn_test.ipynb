{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOCT2c+ab2dC4z1OnaukXkC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumikala/geo.github.io/blob/master/cnn_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bSmmrYyfldf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip airs-dataset.zip -d airs-dataset\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02OkTpFbdYPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorflow==1.1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvpLr6eSdwN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWyLQWy_3SvE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a1769ba4-8886-412e-c95b-9008e43c1b86"
      },
      "source": [
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "print(str(datetime.now()) + ': loading data files')\n",
        "# Data sets\n",
        "trainDataFileName = 'airs-dataset/train.csv'\n",
        "testDataFileName = 'airs-dataset/test.csv'\n",
        "validationDataFileName = 'airs-dataset/valid.csv'\n",
        "# Load datasets.\n",
        "trainData = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
        "    filename=trainDataFileName,\n",
        "    target_dtype=np.int,\n",
        "    features_dtype=np.int)\n",
        "testData = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
        "    filename=testDataFileName,\n",
        "    target_dtype=np.int,\n",
        "    features_dtype=np.int)\n",
        "# validationData = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
        "#     filename=validationDataFileName,\n",
        "#     target_dtype=np.int,\n",
        "#     features_dtype=np.int)\n",
        "\n",
        "trainingSteps = 500\n",
        "totalTrainingSteps = 1500\n",
        "\n",
        "featureColumns = [tf.contrib.layers.real_valued_column(\"\", dimension=75)]\n",
        "hiddenUnits = [100, 150, 100, 50]\n",
        "classes = 2\n",
        "modelDir = 'model'\n",
        "classifierConfig = tf.contrib.learn.RunConfig(save_checkpoints_secs = None, save_checkpoints_steps = trainingSteps)\n",
        "\n",
        "classifier = tf.contrib.learn.DNNClassifier(feature_columns = featureColumns,\n",
        "                                                hidden_units = hiddenUnits,\n",
        "                                                n_classes = classes,\n",
        "                                                model_dir = modelDir,\n",
        "                                                config = classifierConfig)\n",
        "\n",
        "# Define the training inputs\n",
        "def getTrainData():\n",
        "    x = tf.constant(trainData.data)\n",
        "    y = tf.constant(trainData.target)\n",
        "    return x, y\n",
        "\n",
        "# Define the test inputs\n",
        "def getTestData():\n",
        "    x = tf.constant(testData.data)\n",
        "    y = tf.constant(testData.target)\n",
        "    return x, y\n",
        "\n",
        "# Define the validation inputs\n",
        "# def getValidationData():\n",
        "#     x = tf.constant(validationData.data)\n",
        "#     y = tf.constant(validationData.target)\n",
        "#     return x, y\n",
        "\n",
        "# print(str(datetime.now()) + ': training...')\n",
        "# prevAccuracy = -1.0\n",
        "# for i in range(totalTrainingSteps // trainingSteps):\n",
        "#     classifier.fit(input_fn=getTrainData, steps=trainingSteps)\n",
        "#     currentAccuracy = classifier.evaluate(input_fn=getValidationData, steps=1)['accuracy']\n",
        "#     print(str(datetime.now()) + ': training: validation step: ' + str(i) + ' currentAccuracy:', currentAccuracy)\n",
        "#     #if(currentAccuracy <= prevAccuracy):\n",
        "#     #    break\n",
        "#     prevAccuracy = currentAccuracy\n",
        "\n",
        "print(str(datetime.now()) + ': training...')\n",
        "classifier.fit(input_fn=getTrainData, steps=totalTrainingSteps)\n",
        "print(str(datetime.now()) + ': testing...')\n",
        "accuracy = classifier.evaluate(input_fn=getTestData, steps=1)['accuracy']\n",
        "print(str(datetime.now()) + ': done')\n",
        "print(str(datetime.now()) + ': accuracy:', accuracy)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-20 15:23:16.109105: loading data files\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f67566b2f60>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_save_checkpoints_steps': 500, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': None}\n",
            "2020-04-20 15:23:22.812495: training...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
            "Instructions for updating:\n",
            "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Restoring parameters from model/model.ckpt-1001\n",
            "INFO:tensorflow:Saving checkpoints for 1002 into model/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.6111672, step = 1002\n",
            "INFO:tensorflow:global_step/sec: 0.274974\n",
            "INFO:tensorflow:loss = 0.6104703, step = 1102 (363.674 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.271865\n",
            "INFO:tensorflow:loss = 0.61128485, step = 1202 (367.828 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.272584\n",
            "INFO:tensorflow:loss = 0.61073625, step = 1302 (366.860 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.273522\n",
            "INFO:tensorflow:loss = 0.61245966, step = 1402 (365.600 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1502 into model/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.273188\n",
            "INFO:tensorflow:loss = 0.6103688, step = 1502 (366.048 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.274397\n",
            "INFO:tensorflow:loss = 0.6098083, step = 1602 (364.437 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.27243\n",
            "INFO:tensorflow:loss = 0.60963637, step = 1702 (367.066 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.269727\n",
            "INFO:tensorflow:loss = 0.60959274, step = 1802 (370.745 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.26686\n",
            "INFO:tensorflow:loss = 0.60942066, step = 1902 (374.728 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2002 into model/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.263833\n",
            "INFO:tensorflow:loss = 0.61057067, step = 2002 (379.031 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.26416\n",
            "INFO:tensorflow:loss = 0.60915804, step = 2102 (378.555 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.274442\n",
            "INFO:tensorflow:loss = 0.6110318, step = 2202 (364.378 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.275943\n",
            "INFO:tensorflow:loss = 0.60983884, step = 2302 (362.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.274499\n",
            "INFO:tensorflow:loss = 0.6095875, step = 2402 (364.301 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2501 into model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.6102865.\n",
            "2020-04-20 16:55:28.820360: testing...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
            "Instructions for updating:\n",
            "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
            "INFO:tensorflow:Starting evaluation at 2020-04-20-16:55:29\n",
            "INFO:tensorflow:Restoring parameters from model/model.ckpt-2501\n",
            "INFO:tensorflow:Evaluation [1/1]\n",
            "INFO:tensorflow:Finished evaluation at 2020-04-20-16:55:33\n",
            "INFO:tensorflow:Saving dict for global step 2501: accuracy = 0.66666, accuracy/baseline_label_mean = 0.33334, accuracy/threshold_0.500000_mean = 0.66666, auc = 0.45056248, global_step = 2501, labels/actual_label_mean = 0.33334, labels/prediction_mean = 0.27916744, loss = 0.671591, precision/positive_threshold_0.500000_mean = 0.5, recall/positive_threshold_0.500000_mean = 3.00012e-05\n",
            "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
            "2020-04-20 16:55:34.189640: done\n",
            "2020-04-20 16:55:34.189909: accuracy: 0.66666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B28frKGCjIF8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "79ff706c-ebca-4805-903e-89aa4256312e"
      },
      "source": [
        "from datetime import datetime\n",
        "from PIL import Image\n",
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "print(str(datetime.now()) + ': initializing input data...')\n",
        "\n",
        "rectSize = 5;\n",
        "\n",
        "inputImagePath = 'image-input'\n",
        "inputImageFile = '27178705_15.tiff'\n",
        "inputImage = Image.open(inputImagePath + '/' + inputImageFile)\n",
        "inputImageXSize, inputImageYSize = inputImage.size\n",
        "\n",
        "outputImagePath = 'image-output'\n",
        "outputImageFile = '27178705_15.tiff'\n",
        "outputImage = inputImage.crop((rectSize//2, rectSize//2, inputImageXSize - (rectSize//2), inputImageYSize - (rectSize//2)))\n",
        "outputImageXSize, outputImageYSize = outputImage.size\n",
        "\n",
        "print(str(datetime.now()) + ': initializing model...')\n",
        "featureColumns = [tf.contrib.layers.real_valued_column(\"\", dimension=75)]\n",
        "# hiddenUnits = [100, 100, 100, 50]\n",
        "# hiddenUnits = [100, 150, 200, 150, 100, 50]\n",
        "hiddenUnits = [100, 150, 100, 50]\n",
        "classes = 2\n",
        "classifier = tf.contrib.learn.DNNClassifier(feature_columns = featureColumns,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\thidden_units = hiddenUnits,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tn_classes = classes,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tmodel_dir = 'model')\n",
        "\n",
        "def extractFeatures():\n",
        "    features = np.zeros((((inputImageXSize - ((rectSize//2)*2)) * (inputImageYSize - ((rectSize//2)*2))), rectSize*rectSize*3), dtype=np.int)\n",
        "    rowIndex = 0\n",
        "    \n",
        "    for x in range(rectSize//2, inputImageXSize - (rectSize//2)):\n",
        "        for y in range(rectSize//2, inputImageYSize - (rectSize//2)):            \n",
        "            rect = (x - (rectSize//2), y - (rectSize//2), x + (rectSize//2) + 1, y + (rectSize//2) + 1)\n",
        "            subImage = inputImage.crop(rect).load()\n",
        "            colIndex = 0\n",
        "            for i in range(rectSize):\n",
        "                for j in range(rectSize):\n",
        "                    features[rowIndex, colIndex] = subImage[i, j][0]\n",
        "                    colIndex += 1\n",
        "                    features[rowIndex, colIndex] = subImage[i, j][1]\n",
        "                    colIndex += 1\n",
        "                    features[rowIndex, colIndex] = subImage[i, j][2]\n",
        "                    colIndex += 1\n",
        "            \n",
        "            rowIndex += 1\n",
        "    \n",
        "    return features\n",
        "    \n",
        "def constructOutputImage(predictions):\n",
        "    outputImagePixels = outputImage.load()\n",
        "    rowIndex = 0\n",
        "    for x in range(outputImageXSize):\n",
        "        for y in range(outputImageYSize):\n",
        "            outputImagePixels[x, y] = ((255, 255, 255) if predictions[rowIndex] else (0, 0, 0))\n",
        "            rowIndex += 1\n",
        "        \n",
        "print(str(datetime.now()) + ': processing image', inputImageFile)\n",
        "predictions = list(classifier.predict(input_fn=extractFeatures))\n",
        "\n",
        "print(str(datetime.now()) + ': constructing output image...')\n",
        "constructOutputImage(predictions)\n",
        "\n",
        "print(str(datetime.now()) + ': saving output image...')\n",
        "outputImage.save(outputImagePath + '/' + outputImageFile, 'JPEG')\n",
        "\n",
        "print(str(datetime.now()) + ': done')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-20 17:04:49.779000: initializing input data...\n",
            "2020-04-20 17:04:49.825341: initializing model...\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6758360048>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': None}\n",
            "2020-04-20 17:04:49.831114: processing image 27178705_15.tiff\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:335: calling DNNClassifier.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
            "Instructions for updating:\n",
            "Please switch to predict_classes, or set `outputs` argument.\n",
            "INFO:tensorflow:Restoring parameters from model/model.ckpt-2501\n",
            "2020-04-20 17:06:26.249695: constructing output image...\n",
            "2020-04-20 17:06:26.746690: saving output image...\n",
            "2020-04-20 17:06:26.795531: done\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}